---
title: "202-investigate-full"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Taking a step back. What kind of things should I be looking at?

__1__ How good are the data?
__2__ What signals are in the data?
__3__ Random forest search for informative loci
__4__ What about differences between otolith calls?


## Part 1

Let's check our samples for average coverage. On the farm, maybe I can do a one liner (this way isn't the fastest).   
```{sh, eval=FALSE}
srun --partition=high --nodes=1 --time=1-01:00:00 cat bamlists/full.bamlist | while read line; do samtools depth $line | awk '{sum+=$3} END { print sum/NR}' >> outputs/200/full.coverage; done;
```

Now we can look at the distribution of coverage in our samples, and drop the bottom fraction:    

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
samples<-read_tsv("outputs/100/meta2.rda")
bams<-read_tsv("bamlists/full.bamlist",col_names = FALSE) %>% mutate(`Sequence File Name`=gsub(".sort-n.fixmate-m.sort.markdup-r.bam","",X1)) %>% mutate(Bams=X1)
bams$`Sequence File Name`<-gsub("bams/","",bams$`Sequence File Name`)

coverage<-read_tsv("outputs/200/full.coverage", col_names = FALSE)

combined<-inner_join(bams,samples)

combined$Coverage<-coverage$X1

ggplot(combined)+
  geom_histogram(aes(x=Coverage))+
  facet_grid(.~Phenotype)+
  theme_bw()+
  theme(panel.grid = element_blank())+
  xlim(0,20)

filtered<- combined %>% top_frac(.85, Coverage)

ggplot(filtered)+
  geom_histogram(aes(x=Coverage))+
  facet_grid(.~Phenotype)+
  theme_bw()+
  theme(panel.grid = element_blank())+
  xlim(0,20)

filtered %>% select(Phenotype) %>% group_by(Phenotype) %>% summarize(Count=n())
```

Let's replug the association test with these filtered data. Need a .bamlist and a .phenotype file.

```{r, warning=FALSE, message=FALSE}
bams<-select(filtered, `Sequence File Name`) %>% mutate(Path=paste0("bams/",`Sequence File Name`,".sort-n.fixmate-m.sort.markdup-r.bam")) %>% select(Path)
write_tsv(bams, path = "bamlists/partial.bamlist", col_names = FALSE)

phenos<-select(filtered,Phenotype)
phenos$Phenotype<-gsub("FWR",0,phenos$Phenotype)
phenos$Phenotype<-gsub("MIG",1,phenos$Phenotype)
write_tsv(phenos, path = "phenos/partial.phenos", col_names=FALSE)
```

Running 202.1-partial-asso.sh on cluster. Did we get any hits?    
```{r, warning=FALSE, message=FALSE}
data<-read_tsv(file="outputs/200/partial.lrt0.gz")

#Converting to log10p
data <- data %>% mutate(log10p = -log10(dchisq(LRT, df = 1))) %>%
  filter(log10p > 2)

#Check for any significant values
data %>% filter(log10p > 4)
```


## Part 2

There are other options to association tests. First off, I will make a DAPC plot of the two phenotypes and examine the loadings. I can also look a PCA to see some things about the data.   I'll make a *.vcf so I can also prune it later for linked SNPs.   

Runing 202.2-make-vch.sh on cluster. Seg fault again. Switching to making text plink files to convert to .vcf. We can recode and prune linked SNPs.  Plink doesn't like non-human and numerically coded chromosome names, so I'll label them as contig_dd.

```{sh, eval=FALSE}
#in outputs/200
cat partial-vcf.tped | perl -pe 's/^(\d+)\s\d+_/contig_$1 contig_$1_/' > temp.tped
cp partial-vcf.tfam temp.tfam

plink --tped temp.tped --tfam temp.tfam  --out binary --recode --allow-extra-chr --noweb
plink --ped binary.ped --map binary.map --recode vcf --allow-extra-chr -out recode
bcftools +prune -l 0.9 -w 10000 recode.vcf  -Ov -o recode.prune.vcf
```

4719 SNPs!    

```{r,eval=FALSE}
library(adegenet)
library(vcfR)
vcf<-read.vcfR(file="outputs/200/recode.vcf")
genind<-vcfR2genind(vcf)
save(genind, file="outputs/200/recode.genind")
```

```{r, warning=FALSE, message=FALSE}
load("outputs/200/recode.genind")
genind@pop=as.factor(filtered$Phenotype)
dapc<-dapc(genind, n.pca=175, n.da=1)
scatter(dapc, col=c("red","blue"))

contrib <- loadingplot(dapc$var.contr, axis=1,
thres=.0017, lab.jitter=0)

assignplot(dapc)
```

Red is FWR, Blue is MIG.    
     
Plot the allele frequencies and see what the LRT scores are.     
```{r, warning=FALSE,message=FALSE}
vals<-contrib[contrib$var.values>.002]
freq1 <- tab(genind2genpop(genind[loc=c("contig_103_481573")]),freq=TRUE)
freq2 <- tab(genind2genpop(genind[loc=c("contig_58_571477")]),freq=TRUE)

freq1
freq2

data %>% filter(Chromosome %in% c(58,103)) %>% filter(Position %in% c(571477,481573))
```

And of course a PCA following adegenet tutorial.
```{r, warning=FALSE, message=FALSE}
X <- tab(genind, NA.method="mean")

pca1 <- dudi.pca(X,scannf=FALSE,scale=FALSE)
temp <- as.integer(pop(genind))
myCol <- transp(c("red","blue"),.7)[temp]
myPch <- c(15,17)[temp]
## basic plot
plot(pca1$li, col=myCol, cex=1, pch=myPch)
```


Pretty much what we expected except for those extreme values on Axis 1. These are:      
89_1  -27.686470159   6.51236959    
90_1  -27.606702285   4.83477556   

bams/Ht19-20_2012_D03.sort-n.fixmate-m.sort.markdup-r.bam    
bams/Ht19-21_2012_E03.sort-n.fixmate-m.sort.markdup-r.bam   

I wonder what their deal is? Probably should drop them from analyses.

```{r, warning=FALSE, message=FALSE}
nInd(genind)
drop<-c("89_1","90_1")
gen <- genind[!row.names(genind@tab) %in% drop]
nInd(gen)

X2 <- tab(gen, NA.method="mean")

pca2 <- dudi.pca(X2,scannf=FALSE,scale=FALSE)
temp2 <- as.integer(pop(gen))
myCol <- transp(c("red","blue"),.7)[temp]
myPch <- c(15,17)[temp]
## basic plot
plot(pca2$li, col=myCol, cex=1, pch=myPch)
```


What if we assign two groups? I can get about 60-70 % assignment rates back to the original clusters, though unstable, which suggests more of a 50/50 split and this isn't meaningful (not shown)

```{r, echo=FALSE, eval=FALSE, warning=FALSE, message=FALSE}
clust<-find.clusters(gen, n.pca = 100, n.clust = 2)
clust$size
df<-as.data.frame(table(clust$grp, pop(gen)), col.lab=levels(pop(gen))) %>% filter(Freq > 0)
df<-as_tibble(df)
df

plot<-ggplot(df, aes(Var1, Var2))+
  theme(axis.title.y = element_text(size = rel(2)))+
  theme(axis.title.x = element_text(size = rel(2)))+
  theme(axis.text.x = element_text(angle = 90))+
  labs(x="\nInferred Group", y="Phenotype\n")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(text=element_text(family='Times'))+
  theme(axis.text.x= element_text(face="bold", size=10, vjust = 0.5))+
  theme(axis.text.y= element_text(face="bold", size=10))+
  geom_point(aes(x=Var1, y=Var2, size=Freq))+
  scale_size_area(limits=c(1,200), breaks=c(0,25,50,100,150,200))+
  labs(size="Number\nof Individuals")

plot
```
### One more idea, imbalance in samples
This is a problem for machine learning, so I'll generate an equal data set of 72 examples of each class, 144 total samples.


## Part 3
Considering panmictic population, perhaps looking a a machine learning approach to get at if variants can be used to assign fish back to phenotypes may be a smart way to go.  


