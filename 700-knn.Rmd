---
title: "700-knn"
author: "Mac Campbell"
date: "2/20/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Machine Learning
Now with some thinking, why not try KNN classification? It's pretty simple, but maybe that is what we need.

I'll folllow my previous analysis with KNN (https://github.com/MacCampbell/residual-tetrasomy/blob/master/201-classify-and-test.R) which only examined one predictor. Here, we can filter our snps to those that are most predictive, using GWAS results in this case.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(randomForest)
library(ggvis)
library(class)
library(gmodels)
library(viridis)
library(caret)

phenos <- read_tsv("phenos/202.phenos", col_names=FALSE) %>% rename(Pop=X1) %>% mutate(Phenotype=Pop) %>% mutate(Variant=ifelse(Pop==0, "FWR", "MIG"))

#Top one hundred assos
assos<-read_tsv(file="outputs/300/202.lrt0.gz") %>% arrange(-LRT) %>% head(100) %>% mutate(Site=paste(Chromosome,Position, sep="-"))

genos<-read_tsv("outputs/300/202.geno.gz", col_names = FALSE) %>% mutate(Site=paste(X1,X2,sep="-")) 
genos<-genos %>% filter(Site %in% assos$Site)
nrow(genos)
genos$Site

genos<-genos %>% select(-Site)
genos<- genos %>% select(-X205)
genos[genos < 0] <- NA
trans<-as_tibble(t(genos))
trans<-trans[-1:-2,]
trans<-na.roughfix(trans)
```

##With KNN we can use our known samples as a training set.
We don't have even sampling, so let's pull all the FWR and an equal number of MIG, lazily.
```{r, warning=FALSE, message=FALSE}
smeltTrain<-trans[1:122,]
train.labels<-phenos$Variant[1:122]
```

Naively, I can choose k for KNN from sqrt(N), here 61 is our largest class
```{r, warning=FALSE, message=FALSE}
smeltPred <- knn(train = smeltTrain , test = trans, cl = train.labels, k=sqrt(61))

phenos$Prediction <- smeltPred
#phenos$Probability <-round(attr(smeltPred, "prob"),2)

#How did it do?
CrossTable(x = phenos$Phenotype, y = phenos$Prediction, prop.chisq=FALSE)
```

Our I can get a bit more sophisticated about choosing K.
```{r, warning=FALSE, message=FALSE, eval=TRUE}

trControl <- trainControl(method = "repeatedcv",
                          number = 100,
                          repeats = 10)

training<-smeltTrain
training$Type<-train.labels

fit <- train(Type ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = seq(from=1, to=71, by=2)),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = training)
#Note, this chose 21 the first time I tried it
pred <- knn(train = smeltTrain, test = trans, cl = train.labels, k=fit$finalModel$k, prob = TRUE)

phenos$OptKPred<-pred
phenos$OptKProb<-round(attr(pred, "prob"),2)
CrossTable(x = phenos$Phenotype, y = phenos$OptKPred, prop.chisq=FALSE)

```

Let's not forget to look at the fit and k
```{r, warning=FALSE, message=FALSE}
fit$finalModel$k

ggplot(fit)
```

#I did do GWAS with PLINK
```{r, warning=FALSE, message=FALSE}

plink<-read_table(file = "outputs/300/plink-gwas.assoc.adjusted")
plink$Contig<-gsub("_\\d+$","",plink$SNP)
plink$Chrom<-gsub("contig_","",plink$Contig)
plink$Base<-gsub("contig_\\d+_","",plink$SNP)
plink <- plink %>% mutate(Site=paste(Chrom,Base,sep="-"))
#Getting the top .05%
top1<-plink %>% top_frac(-.005, GC) 

genos<-read_tsv("outputs/300/202.geno.gz", col_names = FALSE) %>% mutate(Site=paste(X1,X2,sep="-")) 
genos<-genos %>% filter(Site %in% top1$Site)
nrow(genos)
genos$Site
genos<-genos %>% select(-Site)
genos<- genos %>% select(-X205)
genos[genos < 0] <- NA
trans<-as_tibble(t(genos))
trans<-trans[-1:-2,]
trans<-na.roughfix(trans)

```
```{r, warning=FALSE, message=FALSE}
smeltTrain<-trans[1:122,]
train.labels<-phenos$Variant[1:122]
smeltPred <- knn(train = smeltTrain , test = trans, cl = train.labels, k=sqrt(61))

phenos$Prediction <- smeltPred
#phenos$Probability <-round(attr(smeltPred, "prob"),2)

#How did it do?
CrossTable(x = phenos$Phenotype, y = phenos$Prediction, prop.chisq=FALSE)
```

And to optimize K for this one.
```{r, warning=FALSE, message=FALSE, eval=TRUE}

trControl <- trainControl(method = "repeatedcv",
                          number = 100,
                          repeats = 10)

training<-smeltTrain
training$Type<-train.labels

fit <- train(Type ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = seq(from=1, to=71, by=2)),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = training)
#Note, this chose 21 the first time I tried it
pred <- knn(train = smeltTrain, test = trans, cl = train.labels, k=fit$finalModel$k, prob = TRUE)

phenos$OptKPred<-pred
phenos$OptKProb<-round(attr(pred, "prob"),2)
CrossTable(x = phenos$Phenotype, y = phenos$OptKPred, prop.chisq=FALSE)

```

```{r, warning=FALSE, message=FALSE}
fit$finalModel$k

ggplot(fit)
```
